# 53AI Studio 企业级智能体训练与编排平台

杨芳贤  53AI 内部私享会

## 一、热门场景：AI问答

大家好！我是杨芳贤。在过去的2年里，我们与上百家中大型企业一起深入研究与实践大模型的落地应用，特别是在高准确率的智能问答这一场景下。在今天的分享之前，我先抛出一个问题：怎样能有效地落地大模型，真正为业务创造价值？

#### 面临挑战

我们都知道，大模型技术在过去几年取得了突飞猛进的发展。从GPT-4到Claude，从文心一言到通义千问，各种强大的大模型层出不穷。这些模型在通用能力上表现出色，但落地应用到企业的真实场景中将面临着一系列挑战。

首先是**安全与隐私**的问题。企业数据往往包含敏感信息，直接发送到第三方大模型服务进行处理，存在潜在的数据泄露风险。尤其是在金融、医疗、政府等领域，这一问题尤为突出。

第二是**问答准确性**问题。大模型虽然强大，但在特定领域知识上仍然存在"幻觉"问题，可能生成看似合理但实际上不准确的内容。在企业应用中，错误信息可能导致严重后果，这是不可接受的。

第三是**融入业务**的问题。每个企业都有其独特的业务场景、流程、知识，如何让通用大模型理解业务场景、掌握企业的知识和流程，这不仅是一个技术挑战。

尽管面临这些挑战，企业对大模型技术落地抱着极高的热忱。希望能够以合理的成本，安全地利用大模型的能力，同时确保高准确率和可靠性，并能够灵活适应业务场景。

#### 应用场景

在众多大模型落地场景中，智能问答是当前热度最高的方向。它可以应用在多个关键业务场景中：

在**客户服务**领域，智能问答系统可以7×24小时不间断地回答客户咨询，大幅提升服务效率和客户满意度。数据显示，一个高质量的智能问答系统可以解决60%-80%的常见客户问题，将人工客服的精力释放到更复杂的问题处理上。

在**内部知识管理**方面，企业积累了大量的文档、规章制度、流程指南等知识资产，但员工往往难以高效检索和利用这些信息。智能问答系统可以帮助员工快速找到所需信息，提高工作效率。

在**技术支持**领域，智能问答系统可以帮助技术人员快速定位问题解决方案，减少重复性工作，提高问题解决效率。

在**培训与学习**方面，智能问答系统可以作为个性化学习助手，帮助员工更好地理解和掌握新知识。

传统基于关键词匹配的系统无法理解问题的真正含义，基于规则的系统难以应对灵活多变的自然语言表达；而早期的机器学习模型则缺乏对复杂语境的理解能力。大模型的出现为智能问答系统带来了新的机遇，它们强大的自然语言理解和生成能力可以显著提升问答质量。

如何在保证回答高准确性的前提下，控制成本，保护数据安全？

#### 技术选型

这就引出了我们今天要重点讨论的技术：RAG，全称是Retrieval-Augmented Generation，检索增强生成。简单来说，RAG是一种将检索系统与生成式AI模型结合的技术架构，它先从知识库中检索相关信息，然后将这些信息作为上下文提供给大模型，引导大模型生成更准确、更可靠的回答。

相比纯粹依赖大模型的方案，RAG有几个显著优势：

首先是**更高的准确率**。通过检索企业自身知识库中的权威信息作为上下文，RAG可以显著降低大模型的"幻觉"问题，确保回答基于真实、可靠的信息源。在我们的实践中，采用RAG架构后，系统的回答准确率从原来的70%提升到了95%以上，特定场景甚至能实现99.99%准确率。

其次是**更好的可控性**。企业可以通过管理和更新知识库，直接影响系统的回答内容，而不必依赖于预训练模型中可能已经过时或不准确的知识。

第三是**更低的成本**。RAG架构允许企业使用较小规模的大模型，因为复杂的领域知识不需要完全依赖模型参数来存储，而是可以从外部知识库中检索。这可以显著降低计算资源需求和API调用成本。

第四是**更强的时效性**。企业可以持续更新知识库，确保系统能够提供最新的信息，而不受预训练数据截止日期的限制。

最后是更好的**数据安全性**。敏感信息可以存储在企业自己控制的知识库中，只有必要的、经过处理的信息才会发送给大模型处理，降低了数据泄露风险。

RAG架构的核心组件包括：知识库构建与管理、文本嵌入与向量存储、相似度检索引擎、以及大模型生成模块。整个工作流程是：当用户提出问题时，系统首先将问题转换为向量表示，然后在向量数据库中检索相关信息，将检索到的信息与原始问题一起发送给大模型，最后由大模型生成最终回答。

这种架构巧妙地解决了企业落地大模型的关键痛点：它平衡了成本与效果，保障了数据安全，提高了回答准确性，并且可以灵活适应企业特定的知识体系。

#### 用户故事

第一个是金融机构的客户做的客服场景，这个客户每天面临数万次的客户咨询，涉及复杂的金融产品、政策法规和操作流程。我们帮助他们构建了基于RAG的智能问答系统，将内部知识库、产品手册、法规文件等结构化成向量数据库。系统上线后，自动回答准确率达到了96%，客服人员工作效率提升了40%，客户满意度提升了25%。关键成功因素在于我们对金融领域文档的精细化处理和拆分，以及针对金融场景的提示词工程优化。

第二个是制造业的客户做的技术文档问答场景，这个客户拥有数十万页的技术手册、设备说明书和故障处理指南，技术人员经常需要花费大量时间查找特定信息。我们构建的RAG系统能够理解技术人员的自然语言问题，精准定位到相关文档片段，并生成简洁明了的回答。系统上线后，技术问题解决时间平均缩短了60%，新员工培训周期缩短了30%。这个案例的成功关键在于我们开发的专门针对技术文档的知识抽取算法，以及多级拆分策略。

**小结一下**

RAG作为企业落地大模型的最佳场景，核心优势在于它结合了检索系统的准确性和大模型的灵活性，在保证回答质量的同时，有效控制了成本和风险。它不仅解决了"能用"的问题，更解决了"好用"和"可用"的问题。

但是，要真正将RAG系统应用到生产环境中，仅仅了解其基本原理是远远不够的。我们需要深入理解什么是**高准确率**，以及为什么它对于生产环境至关重要。

---

## 二、高准确率是AI问答上线的基础

正如刚才所提到的，RAG确实是当前企业落地大模型的一个确定性场景。大家有没有发现，当我们将AI系统从测试环境迁移到真实的生产环境时，往往会遇到一个严峻的挑战：准确率的断崖式下降。

今天，我想和大家深入探讨一个核心问题：为什么高准确率对于智能问答系统在生产环境中的成功至关重要？它与测试环境有何不同？我们又该如何定义和衡量这种准确率？

#### 生产环境与测试环境的差异

首先，让我们来看看生产环境与测试环境之间存在哪些本质差异。

在生产环境中，系统面对的是真实用户的多样化需求。用户的问题表达方式千差万别，可能包含各种行业术语、方言表达、甚至错别字和语法错误。比如同样是询问"如何重置密码"，有人可能会问"怎么改密码"，有人可能会问"账号登不进去了怎么办"，还有人可能会问"密码忘了咋整"。这种表达的多样性远远超出测试集的覆盖范围。

其次，生产环境中的查询模式是不可预测的。用户可能会提出系统设计者从未考虑过的问题，或者以设计者未曾预料的方式组合多个问题。例如，一个简单的"你们的退货政策是什么"可能会演变成"如果我在618买的产品，现在发现有质量问题，但已经超过30天，还能按照活动价退货吗？"

第三，生产环境通常需要处理高并发请求，系统必须在保证准确率的同时，维持稳定的响应速度和服务质量。当系统负载增加时，如果没有良好的架构设计和优化，准确率可能会受到影响。

最关键的是，在生产环境中，用户对错误的容忍度极低。一个在测试环境中被认为"还不错"的90%准确率，在生产环境中可能意味着每10个用户中就有1个得到错误信息，这对企业声誉和用户信任度的损害是巨大的。

这就是刚才提到的"准确率断崖"现象——系统在从测试环境迁移到生产环境时，准确率可能会出现显著下降。在我们的实践中，曾经遇到过一个系统在测试环境中准确率高达95%，但部署到生产环境后，实际准确率却下降到了65%以下。这种差距主要源于测试数据无法完全模拟真实世界的复杂性和多样性。

#### 高准确率的定义与衡量标准

那么，对于AI问答，什么才是"高准确率"？这个问题比看起来要复杂得多，因为准确率实际上是一个多维度的概念。

首先是**检索准确率**，它衡量系统找到相关信息的能力。一个高检索准确率的系统应该能够从知识库中准确找出与用户问题最相关的信息片段。这通常通过召回率（Recall）和精确率（Precision）来衡量。召回率反映了系统能够找到多少相关信息，而精确率则反映了找到的信息中有多少是真正相关的。

其次是**回答准确率**，它衡量系统基于检索结果生成正确回答的能力。即使检索到了正确的信息，大模型也可能在生成回答时出现理解错误、推理错误或表达不清等问题。回答准确率通常需要通过人工评估或与标准答案比对来衡量。

第三是**拒答准确率**，它衡量系统识别自己无法回答问题的能力。一个优秀的系统应该知道自己的能力边界，当遇到知识库中没有覆盖的问题时，应该明确表示无法回答，而不是生成看似合理但实际上不准确的回答。这一点对于企业应用尤为重要，因为错误信息可能导致严重后果。

在评估这些准确率时，我们通常会采用多种方法和指标：

定量指标方面，除了传统的准确率、召回率、F1值等，我们还会关注Mean Reciprocal Rank（平均倒数排名）、NDCG（归一化折扣累积增益）等更细致的评估指标。这些指标可以从不同角度反映系统的性能。

定性评估方面，用户满意度调查和业务专家评审也是不可或缺的。我们会让客户定期安排业务专家对系统回答进行评估，并收集真实用户的反馈，这些信息往往能揭示纯粹依靠数字指标无法发现的问题。

在企业级场景中，我们通常将95%以上的综合准确率作为上线目标。这意味着系统需要在**检索准确率**、**回答准确率**和**拒答准确率**三个维度上都达到很高的水平。这是一个富有挑战的目标，但对于需要在生产环境中长期稳定运行的系统来说，这是必要的。

#### 准确率对用户体验的影响

为什么我们如此**强调准确率**？因为在生产环境中，错误回答可能带来严重的后果。

首先是用户**信任度的快速下降**。研究表明，用户对AI问答的信任是脆弱的，一次明显的错误回答可能导致用户长期对系统持怀疑态度。有调查数据显示，78%的用户表示，如果AI问答给出明显错误的信息，他们会显著降低对该系统的使用频率。

其次，在企业环境中，错误信息可能导致**错误的业务决策**。想象一下，如果一个销售人员依赖智能问答系统向客户介绍产品功能，而系统提供了错误信息，这不仅可能导致流失，还可能引发合规风险。

第三，错误回答会**损害企业品牌声誉**。在社交媒体时代，一个AI系统的明显错误可能被迅速放大并广泛传播，对企业形象造成负面影响。

更严重的是，在某些领域，如医疗、金融、法律等，错误信息可能带来潜在的法律风险。如果用户基于系统提供的错误信息做出重要决策，企业可能面临法律责任。

有意思的是，用户对AI问答和人工服务的期望是不同的。有研究显示，用户对AI问答的错误容忍度通常低于对人类的错误容忍度。当人类客服犯错时，用户往往理解这是"人之常情"；但当AI问答犯同样的错误时，用户会质疑整个系统的可靠性。

准确率与用户采纳率之间存在明显的相关性。在我们的一个项目中，当系统准确率从85%提升到95%时，用户的日活跃度增加了40%，重复使用率增加了60%。这表明，准确率的提升不仅是技术指标的改善，更直接影响到系统的商业价值。

#### RAG系统的准确率挑战

那么，对于RAG系统来说，影响准确率的关键因素有哪些呢？

首先是**语料数据的质量与覆盖面**。语料数据是RAG系统的基础，如果语料数据的信息不准确、不完整或过时，即使有最先进的检索和生成算法，也无法产生高质量的回答。因此，语料数据库的建设和维护是RAG系统成功的关键。

其次是**检索算法的精准度**。检索算法需要准确理解用户问题的意图，并找到最相关的信息片段。这涉及到语义理解、相似度计算、排序算法等多个技术环节，每一环节的优化都会直接影响系统的整体准确率。

第三是**大模型的理解与生成能力**。大模型需要正确理解检索到的信息，并基于这些信息生成准确、连贯、符合用户期望的回答。不同大模型在这方面的能力有显著差异，选择合适的模型并进行适当的参数调整是提升准确率的重要手段。

最后是**提示工程**（Prompt Engineering）的优化。在RAG系统中，如何构建有效的提示词，引导大模型正确理解和利用检索信息，是一门既需要技术能力又需要领域知识的艺术。

在过去实践中，我们也发现了一些常见的准确率陷阱与误区：

一是**过度依赖测试集准确率**。如前所述，测试环境与生产环境存在本质差异，仅仅依靠测试集上的高准确率并不能保证系统在实际应用中的表现。

二是**忽视拒答能力的培养**。许多团队过于关注系统能回答的问题，而忽视了"知道自己不知道"的能力，这在生产环境中可能导致严重的误导。

三是**忽略他性能指标**。在追求高准确率的同时，系统的响应速度、资源消耗等指标也需要保持在合理范围内。过度追求准确率可能导致系统变得缓慢或成本过高。

**小结一下**

高准确率是AI问答系统在生产环境中成功的基础。它不仅关系到用户体验和信任度，还直接影响系统的商业价值和企业声誉。要实现高准确率，我们需要从多个维度进行评估和优化，包括检索准确率、回答准确率和拒答准确率。

而要构建一个高准确率的RAG系统，首先需要解决的是语料数据的质量问题。**"垃圾进，垃圾出"（Garbage In, Garbage Out）**，无论我们的算法多么先进，如果底层的语料数据质量不佳，系统的表现也会受到限制。

---

## 三、语料知识整理的方法论

正如前面所提到的，**"垃圾进，垃圾出"**（Garbage In, Garbage Out）在RAG系统中体现得尤为明显。无论我们的检索算法多么先进，大模型多么强大，如果底层的语料数据质量不佳，系统的表现必然会受到限制。

我想和大家分享的一个观点：**语料知识整理是构建高准确率RAG系统的基石**。在我们的实践中，同样的模型和算法，在优化语料数据后，系统准确率可以提升20%以上。接下来，我将详细介绍企业级语料知识库的特点与挑战，以及53AI的语料知识库整理的方法论。

#### 企业级语料知识库的特点与挑战

企业的语料数据库与互联网上的公开数据有着本质区别，它具有一些独特的特征，这些特征也带来了特殊的挑战。

首先是**数据来源的多样性**。一个企业可能包含多种类型的信息源：产品手册、技术文档、内部wiki、培训材料、客户反馈、会议记录、邮件往来、甚至是专家经验等。这些信息分散在不同的系统和平台上，如何有效地整合这些数据源，是第一个需要解决的问题。

其次是**格式的异构性**。企业数据通常包含结构化数据（如数据库中的表格数据）、半结构化数据（如JSON、XML文件）和非结构化数据（如文本文档、图片、视频）。不同格式的数据需要不同的处理方法，如何将它们统一转化为RAG系统可用的格式，涉及到的文档的抽取及语料拆分是一个蛮大的技术挑战。

第三是**专业术语与领域知识的密集性**。企业文档中通常充满了行业术语、公司特有的缩写和专业概念，这些内容对于通用模型来说可能是难以理解的。例如，同一个缩写"CRM"在大多数行业指的是"客户关系管理"，而在医疗行业可能指"临床风险管理"。

最后是**时效性与更新频率**的问题。企业知识是不断演进的，产品更新、政策变化、流程优化等都会导致知识库需要及时更新。建立一个能够持续更新且保持一致性的管理机制，是确保RAG系统长期文档运行的关键。

在实际工作中，我们还经常遇到一些典型的语料数据库的建设痛点：

1、数据质量不一：来自不同来源的数据质量参差不齐，有些可能包含错误信息或过时内容。

2、知识更新滞后：新知识的产生与录入知识库之间存在时间差，导致系统无法回答最新问题。

3、缺乏统一标准：不同团队使用不同的格式和标准记录知识，增加了整合难度。

这些挑战看似繁多，但通过系统化的语料数据整理方法，是可以逐一克服的。

#### 语料知识整理的流程与方法

基于我们的实践经验，我们总结了一套端到端的语料数据整理流程，包括五个关键步骤：

第一步是**数据源识别与接入**。这一步需要全面梳理企业内部的知识资产，确定哪些数据源需要纳入RAG系统的语料数据库。在这个过程中，我们需要与业务部门密切合作，了解用户最常咨询的问题类型，然后有针对性地**确定优先级最高的数据源**。例如，对于客服场景，常见问题解答（FAQ）、产品手册、政策文件通常是首要数据源；而对于内部知识管理，则可能更关注流程文档、培训材料和最佳实践案例。在数据源确定后，我们需要建立数据接入机制。对于结构化数据，可以通过API或数据库连接直接获取；对于文档类数据，需要文件系统接入或文档管理系统的API；对于邮件、聊天记录等非正式数据，则可能需要特定的提取工具。理想情况下，可以建立自动化的数据接入流程，确保语料数据库能够及时获取最新信息。

第二步是**数据清洗与预处理**。原始数据通常包含大量噪音和冗余信息，需要进行清洗和预处理。这包括：

1、去除无关内容：如页眉页脚、导航菜单、版权声明等。
2、修正格式问题：如乱码、特殊字符、不规范的换行等。
3、内容合并去重：识别并合并重复或高度相似的内容。
4、拼写和语法检查：修正明显的拼写错误和语法问题。
5、合适标准化：将不同来源的数据转换为统一的格式和编码。

在这一步中，我们通常会结合自动化清洗工具加上人工审核。例如，使用数据清洗工具批量处理常见的格式问题，然后由业务专家抽样，确保没有丢失重要信息。

第三步是**格式标准化与结构化**。清洗后的数据需要转换为统一的格式，便于后续处理。对于文本数据，我们通常会将其转换为纯文本或Markdown格式；对于表格数据，可能会转换为CSV或JSON格式；对于包含图表的文档，我们需要提取图表中的关键信息并转化为文本描述。

在这一步中，我们还会尝试为非结构化数据添加结构。例如，识别文档中的标题、段落、列表等结构元素，提取文档的层次结构，识别关键实体和关系等。这些结构信息对于后续的知识抽取和检索非常有价值。

第四步是**元数据管理**。元数据是描述数据的数据，包括数据的来源、创建时间、最后更新时间、作者、适用范围、关键词等信息。完善的元数据管理可以帮助系统更好地理解和组织知识，提高检索精度，并支持知识的版本控制和权限管理。

在实践中，我们会为每个知识片段定义一套标准的元数据字段，并确保这些字段在数据处理过程中得到正确填充。例如，对于产品手册，我们会记录产品型号、适用版本、发布日期等信息；对于政策文件，则会记录政策编号、生效日期、失效日期等信息。

第五步是**版本控制与更新机制**。知识是不断演进的，我们需要建立机制确保知识库能够及时反映最新信息。这包括：

1、定期同步：与源系统建立定期同步机制，自动获取更新的内容。
2、变更检测：开发算法检测文档的重要变更，优先处理发生重大变化的内容。
3、版本管理：保留知识的历史版本，必要时可以回溯查看历史信息。
4、更新日志：记录每次更新的内容和原因，便于审计和问题排查。

对于不同类型的文档，我们需要采用不同的处理策略：

1、文本文档（Word、PDF、TXT等），我们会使用文本提取工具获取纯文本内容，然后进行结构识别和语义分析。对于PDF文档，可能还需要OCR技术处理扫描件或图片中的文字。

2、表格数据（Excel、CSV等），我们会关注数据的结构和语义，将表格转换为结构化数据，并添加必要的上下文说明，确保数据的可解释性。

3、图像与多媒体内容，我们会提取其中的文字信息，并添加描述性文本，使这些非文本内容也能被检索和理解。

4、代码与技术文档，我们会保留其特殊的格式和结构，同时提取注释和说明文字，建立代码与说明之间的关联。

在整个过程中，自动化清洗工具与人工审核的结合至关重要。我们会构建自动化的数据处理流水线，处理大部分常规任务，然后由业务专家进行抽样审核和质量控制，确保处理结果符合预期。

#### 数据质量控制的关键点

高质量的语料数据是RAG系统成功的基础，那么如何评估和控制数据质量呢？

我们通常从五个维度进行评估：

**完整性**：知识库是否覆盖了用户可能咨询的所有重要领域？是否存在明显的知识空白？我们通常会通过用户查询日志分析和专家评审来识别知识覆盖的盲点。

**准确性**：知识库中的信息是否准确无误？是否存在错误或误导性内容？这通常需要领域专家的审核和验证。在实践中，我们会建立多级审核机制，确保关键信息的准确性。

**一致性**：不同来源的知识是否存在矛盾或冲突？术语和概念的使用是否统一？我们会使用自动化工具检测潜在的矛盾，并通过建立术语表和知识图谱来提高一致性。

**时效性**：知识是否是最新的？是否包含过时的信息？我们会为每个知识片段添加时间戳和有效期信息，并建立定期审核机制，确保重要知识的及时更新。

**可用性**：知识的表达是否清晰易懂？是否适合机器处理和检索？我们会评估知识的结构化程度、语言表达的规范性等因素。

为了保证这些维度的质量，我们会采用多种技术手段：

**自动检测工具**：开发算法检测常见的质量问题，如拼写错误、格式不一致、缺失字段等。

**异常值识别**：使用统计方法和机器学习算法识别可能存在问题的异常数据，如异常长度的文档、包含异常术语的段落等。

**冗余与矛盾检测**：开发算法检测知识库中的冗余内容和潜在矛盾，确保知识的一致性。

**专家审核机制**：建立领域专家参与的审核流程，特别是对关键知识点和高风险领域的内容进行重点审核。

除了初始质量控制外，持续的质量监控也非常重要。我们会建立反馈循环机制，收集系统运行过程中的问题和用户反馈，不断优化和更新知识库。例如，通过分析用户查询中的"无法回答"案例，识别知识库的覆盖盲点；通过用户反馈识别可能存在错误的回答，及时修正相关知识。

**语料数据库管理的最佳实践**

基于我们的实践经验，分享几点语料数据库管理的最佳实践：

首先是**语料数据库架构设计原则**。一个良好的知识库架构应该是模块化的，便于扩展和维护。我们通常会按照业务领域或知识类型划分知识库，建立清晰的层次结构。同时，知识库应该支持多种访问方式，满足不同场景的需求。

其次是**元数据标准与分类体系**。统一的元数据标准和分类体系是知识库管理的基础。我们会定义核心元数据字段，如知识类型、适用范围、重要程度、更新频率等，并建立分类体系，便于知识的组织和检索。

第三是**知识图谱的应用**。知识图谱可以帮助我们捕捉实体之间的关系，提供更丰富的语义信息。例如，在产品领域，我们可以建立产品、功能、规格、适用场景等实体之间的关系网络，帮助系统更好地理解和回答复杂查询。

第四是**权限管理与安全控制**。企业的语料数据库通常包含敏感信息，需要严格的权限管理和安全控制。我们会建立基于角色的访问控制机制，确保用户只能访问其有权限的知识，并对敏感操作进行审计和记录。

最后是**语料数据库的维护策略**。预料数据库不是一次性建设的项目，而是需要持续投入的资产。我们会建立定期审核和更新机制，确保知识的时效性和准确性。同时，我们也会关注用户反馈和系统表现，不断优化知识库的质量和覆盖范围。

**小结一下**

高质量的语料数据整理是构建高准确率RAG系统的基石。通过系统化的数据源识别、数据清洗、格式标准化、元数据管理和版本控制，我们可以建立一个完整、准确、一致、及时且可用的语料数据库，为RAG系统稳定运行提供坚实的基础。

---

## 四、语料知识的数据拆分

语料知识的数据拆分的粒度和策略直接影响检索精度，进而影响整个RAG系统的准确率。在我们的实践中，仅仅通过优化拆分策略，系统的准确率就提升了15%以上，而无需改变任何模型或算法。接下来，我将详细介绍语料拆分的意义与挑战，不同拆分粒度的影响，以及拆分策略的选择与优化。

#### 语料知识的数据拆分的意义与挑战

首先，让我们明确一下什么是语料拆分。简单来说，语料拆分是将长文档分割成更小的片段或"块"(chunks)的过程，这些块将作为RAG系统的基本检索单位。当用户提出问题时，系统会检索最相关的块，而不是整个文档。

语料拆分在RAG系统中具有几个关键作用：

首先，它能**显著提高检索精度**。想象一下，如果我们以整个文档为检索单位，当用户询问一个具体问题时，系统可能会返回包含相关信息但同时也包含大量无关信息的整个文档。这不仅会增加大模型的处理负担，还可能导致回答不聚焦或被无关信息干扰。通过将文档拆分成适当大小的块，我们可以更精准地定位与问题相关的内容。

其次，拆分可以**减少无关信息的干扰**。大模型在生成回答时，会考虑提供的所有上下文信息。如果上下文中包含大量与问题无关的内容，可能会导致模型生成偏离主题或不准确的回答。适当的拆分可以确保检索结果更加聚焦，减少噪音。

第三，拆分可以**优化向量存储的效率**。较小的文本块可以生成更精确的向量表示，提高语义检索的准确性。同时，适当大小的块也有利于向量数据库的索引和查询效率。

最后，拆分**有助于增强语义理解**。通过将相关内容组织在一起，形成语义连贯的块，可以帮助模型更好地理解上下文和概念之间的关系。

然而，语料拆分也面临一系列挑战：

最大的挑战是**语义完整性与拆分粒度的矛盾**。如果拆分粒度过大（块太大），会包含过多可能无关的信息；如果拆分粒度过小（块太小），可能会破坏语义完整性，导致上下文信息丢失。例如，一个复杂的技术解释可能跨越多个段落，如果我们简单地按段落拆分，可能会割裂这个完整的解释。

其次是**上下文信息的保留问题**。某些信息需要结合前后文才能完全理解，简单的机械拆分可能会丢失这种上下文。例如，代词引用（"它"、"这个"等）通常需要前文来确定指代对象；条件陈述（"如果...那么..."）可能跨越多个段落。

第三是**跨段落关系的维护**。文档中的不同部分可能存在引用、补充或对比关系，简单拆分可能会丢失这些关系。例如，一个章节可能引用了前面章节的概念或数据，如果这两部分被拆分到不同的块中，这种关联可能会丢失。

最后是**不同类型文档的差异化处理**。不同类型的文档（如技术手册、政策文件、FAQ等）具有不同的结构和语义特点，需要采用不同的拆分策略。例如，FAQ文档中的问答对通常应该保持在同一个块中；而长篇技术文档可能需要更复杂的层次化拆分。

#### 不同拆分粒度的影响

在实践中，我们通常采用以下几种拆分策略，接下来介绍以下各种才分粒度的优缺点：

1、**文档级拆分**是最简单的方式，即将每个完整文档作为一个检索单位。这种方式的优点是保持了文档的完整语义，不会丢失任何上下文信息；缺点是检索精度低，尤其是对于长文档，可能会返回大量与查询无关的内容，增加后续处理的负担。在我们的测试中，对于平均长度超过10页的文档，文档级拆分的检索准确率通常不超过60%。

2、**章节级拆分**是按文档的自然章节结构进行拆分。这种方式的优点是尊重了文档的原有结构，章节通常具有相对完整的语义；缺点是章节大小可能差异很大，有些章节可能仍然过大，不利于精确检索。我们发现，章节级拆分适合结构清晰的正式文档，如技术规范、政策手册等。

3、**段落级拆分**是最常用的方式，将文档按段落进行拆分。这种方式的优点是平衡了语义完整性和检索精度，段落通常是一个完整的语义单位；缺点是可能会丢失跨段落的上下文信息。在大多数通用场景下，段落级拆分是一个不错的起点，但通常需要进一步优化。

4、**句子级拆分**是最细粒度的常见拆分方式。这种方式的优点是检索精度非常高，可以精确定位到与查询最相关的句子；缺点是严重缺乏上下文，单个句子通常无法提供完整的信息。在我们的测试中，纯句子级拆分通常会导致回答不完整或缺乏必要的解释。

5、**混合级拆分**是结合多种粒度的拆分策略。例如，可以先按章节拆分，然后对较大的章节进一步按段落拆分；或者根据内容的语义相关性，动态调整拆分粒度。这种方式的优点是灵活性高，可以根据内容特点进行优化；缺点是实现复杂度高，需要更多的算法支持。

拆分粒度对检索性能的影响是多方面的：

在准确率与召回率的权衡方面，**较小的拆分粒度能提高检索的准确率，但会降低召回率**（因为相关信息可能分散在多个块中）；较大的拆分粒度则相反，可能提高召回率但降低准确率。在实践中，我们需要根据具体应用场景找到最佳平衡点。

在计算资源消耗方面，**拆分粒度越小，生成的块数量越多，向量数据库的规模也越大**，这会增加存储和检索的计算成本。例如，将一个10万字的文档按每500字拆分，会生成200个块；而按每100字拆分，则会生成1000个块，存储和检索成本相应增加5倍。

在用户体验方面，**拆分粒度会影响系统的响应速度和回答质量**。过大的拆分粒度可能导致回答冗长、不聚焦；过小的拆分粒度可能导致回答片段化、缺乏连贯性。最佳的拆分策略应该能够提供既准确又连贯的回答，同时保持合理的响应速度。

#### 拆分策略的选择与优化

基于我们的实践经验，拆分策略的选择和优化可以从三个方向考虑：

**1、基于规则的拆分方法**，是最简单也是最常用的方法

固定长度拆分是最基础的方法，按照固定的字符数或token数进行拆分。例如，每512个token作为一个块。这种方法的优点是实现简单，计算效率高；缺点是可能会割裂语义单位，导致上下文丢失。在实践中，我们通常会结合滑动窗口技术，让相邻块之间有一定的重叠，减少信息丢失。

基于标点与段落的拆分是更尊重文本自然结构的方法。这种方法会在段落边界或句子边界进行拆分，避免割裂完整的语义单位。例如，可以优先在段落结束处拆分，如果段落过长，则在句号、问号等句子结束的标点处拆分。这种方法的优点是能够保持基本的语义完整性；缺点是可能导致块大小不均，需要额外的处理来控制块大小。

基于文档结构的拆分利用文档的原有结构进行拆分，如标题、章节、列表等。这种方法特别适合结构化程度高的文档，如技术手册、学术论文等。通过识别文档的层次结构，可以更智能地进行拆分，保持相关内容的完整性。例如，可以确保一个标题及其下属内容保持在同一个块中，除非内容过长需要进一步拆分。

**2、语义感知的智能拆分**，是更先进的方法，它考虑了文本的语义特性

基于主题的拆分尝试识别文本中的主题变化，在主题转换处进行拆分。这种方法可以确保每个块都围绕一个相对完整的主题，提高语义连贯性。实现方式包括使用主题模型（如LDA）识别主题变化点，或使用语义相似度计算相邻段落的相似程度，在相似度显著下降处进行拆分。

基于语义相似度的拆分是通过计算文本片段之间的语义相似度，将语义相似的内容组合在一起。这种方法可以克服传统基于位置的拆分可能导致的语义割裂问题。例如，即使两个段落在文档中相隔较远，但如果它们讨论的是同一个概念或主题，也可以考虑将它们组合在一起。

基于实体与关系的拆分关注文本中的关键实体和它们之间的关系，确保相关的实体及其关系描述保持在同一个块中。这种方法特别适合知识密集型文档，如百科全书、技术规范等。通过识别文本中的关键实体和关系，可以更智能地组织内容，提高检索的精准度。

**3、混合拆分策略**，结合了多种方法的优点，是最灵活也最有效的方法：

多级拆分与层次索引是一种先粗后细的方法。首先按较大粒度（如章节）进行拆分，建立一级索引；然后对每个大块再进行细粒度拆分（如段落或句子），建立二级索引。检索时，先在一级索引中找到相关章节，再在二级索引中精确定位。这种方法既提高了检索精度，又保持了计算效率。

自适应拆分算法能够根据内容特点动态调整拆分策略。例如，对于信息密度高的技术内容，可能采用更细的拆分粒度；对于叙述性内容，可能采用更粗的拆分粒度。这种方法需要更复杂的算法支持，但能够更好地适应不同类型的内容。

领域特定拆分规则是针对特定领域或文档类型定制的拆分策略。例如，对于法律文档，可能需要特别关注条款和引用关系；对于医疗文档，可能需要特别关注疾病、症状和治疗方法之间的关系。通过结合领域知识，可以开发出更有效的拆分规则。

#### 实践中的经验分享

在实际项目中，我们发现不同行业和文档类型通常需要不同的拆分策略：

对于**金融行业的文档**，如年报、招股说明书等，我们采用了基于结构的多级拆分策略。首先按章节拆分，然后对财务数据部分采用更细粒度的拆分，确保能够精确回答关于具体财务指标的查询。这种策略将检索准确率从初始的70%提升到了92%。

对于**技术文档**，如API文档、技术手册等，我们发现基于语义单位的拆分效果最好。例如，将每个API方法及其参数、返回值、示例代码等作为一个完整的块，即使这个块可能较大。这种方法确保了技术信息的完整性，提高了回答的准确性。

对于**客服FAQ文档**，我们采用了问答对作为基本拆分单位，确保每个问题及其回答保持在同一个块中。同时，我们还建立了问题之间的语义关联，当一个问题的回答引用了另一个问题时，系统能够自动关联这些相关内容。

通过这些优化的拆分策略，我们在不同项目中实现了显著的准确率提升。例如，在一个客服智能问答系统中，仅通过优化拆分策略，准确率就从83%提升到了95%，用户满意度提升了30%。

**小结一下**

语料拆分是RAG系统中一个看似简单但实际上至关重要的环节。合适的拆分策略可以显著提高检索精度，进而提升整个系统的准确率。在实践中，我们需要根据具体的应用场景和文档特点，选择和优化拆分策略，可能是基于规则的方法、语义感知的智能拆分，或者是混合拆分策略。

然而，即使我们有了高质量的语料数据、准确的知识抽取和优化的拆分策略，RAG系统在实际运行中仍然可能遇到各种问题。如何快速定位和解决这些问题，是确保系统持续高准确率的关键。

希望今天的分享对大家有所帮助，感谢各位的聆听！
